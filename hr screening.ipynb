{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPqarl/76FMEqhwzZOhLZ1v"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["import torch\n","print(\"GPU available:\", torch.cuda.is_available())\n","print(\"Device name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU\")"],"metadata":{"id":"EUbowk7bmXtw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Install Libraries\n","!pip install -q twilio pydub\n","!pip install git+https://github.com/huggingface/parler-tts.git\n","!pip install faster-whisper"],"metadata":{"id":"63gvmvLjUoUt","collapsed":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Import Dependencies\n","import json\n","import time\n","import requests\n","from twilio.rest import Client\n","from pydub import AudioSegment\n","from faster_whisper import WhisperModel"],"metadata":{"id":"yFSPRI0HUrx1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Twilio Setup -  for calling and recording you can get all these info when you create an account on twilio\n","import os\n","TWILIO_ACCOUNT_SID = input(\"Enter your Twilio Account SID: \") # Your Twilio SID\n","TWILIO_AUTH_TOKEN = input(\"Enter your Twilio Auth Token: \")    # Your Twilio Auth Token\n","TWILIO_PHONE_NUMBER = input(\"Enter your Twilio Phone Number: \")   # Your Twilio Number (e.g., +1415xxxxxx)\n","TWIML_BIN_URL = input(\"Enter your TwiML Bin URL: \") #url created in twiml bin in xml for twilio calling tone and audio like what to speak\n","OPENROUTER_API_KEY = input(\"Enter your OpenRouter API Key: \")\n","MODEL = input(\"Enter Your Model Name: \")\n","\n","client = Client(TWILIO_ACCOUNT_SID, TWILIO_AUTH_TOKEN)"],"metadata":{"id":"ikYgN8nVUruo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# this will ask for candidate's mobile number then Triggers the Call\n","CANDIDATE_PHONE = input(\"Enter candidate number (e.g., +91xxxxxxxxxx): \")\n","call = client.calls.create(\n","    to=CANDIDATE_PHONE,\n","    from_=TWILIO_PHONE_NUMBER,\n","    url=TWIML_BIN_URL\n",")\n","\n","print(\"Call initiated. SID:\", call.sid)"],"metadata":{"id":"IRVhF-UuUrsA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"Waiting 20 seconds for call and recordings to complete...\")\n","time.sleep(20)\n","\n","# Fetch recordings\n","recordings = client.recordings.list(call_sid=call.sid)\n","print(f\"\\n Found {len(recordings)} recording(s)\")\n","\n","# Load Whisper model\n","model = WhisperModel(\"medium\", compute_type=\"float16\")\n","\n","conversation_log = []\n","\n","# Process & Transcribe each recording\n","for idx, rec in enumerate(recordings):\n","    audio_url = f\"https://api.twilio.com{rec.uri.replace('.json', '.wav')}\"\n","    response = requests.get(audio_url, auth=(TWILIO_ACCOUNT_SID, TWILIO_AUTH_TOKEN))\n","\n","    # Save original recording\n","    raw_file = f\"response_{idx+1}.wav\"\n","    with open(raw_file, \"wb\") as f:\n","        f.write(response.content)\n","\n","    # Resample to 16kHz mono\n","    sound = AudioSegment.from_file(raw_file)\n","    sound = sound.set_frame_rate(16000).set_channels(1)\n","    processed_file = f\"processed_{idx+1}.wav\"\n","    sound.export(processed_file, format=\"wav\")\n","\n","    # Transcribe using Whisper\n","    segments, _ = model.transcribe(processed_file, beam_size=5)\n","    candidate_response = \" \".join([seg.text.strip() for seg in segments])\n","\n","    conversation_log.append({\n","        \"agent\": f\"Q{idx+1}\",\n","        \"candidate\": candidate_response\n","    })\n","\n","# Print Final Conversation Log\n","print(\"\\n Final Transcription Log:\\n\")\n","for turn in conversation_log:\n","    print(f\"{turn['agent']}: {turn['candidate']}\")"],"metadata":{"id":"YRn4k3F6UrpQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# LLM Prompt for candidate's review\n","prompt = f\"\"\"\n","You are a recruitment AI assistant. Here's the transcript of a candidate interview:\n","\n","---\n","{conversation_log}\n","---\n","\n","Your tasks:\n","1. Detect sentiment and tone (positive, negative, neutral, confident, hesitant, confused).\n","2. Identify key information: skills, experience, location, willingness to join.\n","3. Determine if the candidate asked a question that needs human escalation and note the questions.\n","4. Recommend a decision: Shortlist, Escalate, or Hold.\n","5. Suggest a closing response line.\n","\n","Respond in JSON format with keys:\n","{{\n","  \"Sentiment\": \"\",\n","  \"Tone\": \"\",\n","  \"Skills\": [],\n","  \"Experience\": \"\",\n","  \"Location\": \"\",\n","  \"Willing_to_Join\": true,\n","  \"Candidate_Asked_Question\": false,\n","  \"Candidate_Asked_Questions_List\": [],\n","  \"Decision\": \"\",\n","  \"Closing_Line\": \"\"\n","}}\n","\"\"\""],"metadata":{"id":"b3VSiLwCVqWO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Call LLM\n","\n","\n","headers = {\n","    \"Authorization\": f\"Bearer {OPENROUTER_API_KEY}\",\n","    \"Content-Type\": \"application/json\"\n","}\n","\n","payload = {\n","    \"model\": MODEL,\n","    \"messages\": [\n","        {\"role\": \"system\", \"content\": \"You are a helpful recruitment AI assistant.\"},\n","        {\"role\": \"user\", \"content\": prompt}\n","    ]\n","}\n","\n","response = requests.post(\"https://openrouter.ai/api/v1/chat/completions\", headers=headers, json=payload)"],"metadata":{"id":"P8FKcb7uV0nj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import re\n","\n","try:\n","    llm_output_raw = response.json()[\"choices\"][0][\"message\"][\"content\"]\n","\n","    # Strip markdown-style formatting like ```json\n","    llm_output_clean = re.sub(r\"```json|```\", \"\", llm_output_raw).strip()\n","\n","    # Convert to dictionary\n","    final_output = json.loads(llm_output_clean)\n","\n","    # Pretty Output (like a report)\n","    print(\"\\n==============================\")\n","    print(\" Candidate Screening Summary\")\n","    print(\"==============================\\n\")\n","\n","    print(f\"-> Sentiment       : {final_output.get('Sentiment', 'N/A')}\")\n","    print(f\"-> Tone            : {final_output.get('Tone', 'N/A')}\")\n","    print(f\"-> Experience      : {final_output.get('Experience', 'N/A')}\")\n","    print(f\"-> Skills          : {', '.join(final_output.get('Skills', []))}\")\n","    print(f\"-> Location        : {final_output.get('Location', 'N/A')}\")\n","    print(f\"-> Willing to Join : {'Yes' if final_output.get('Willing_to_Join') else 'No'}\")\n","    print(f\"-> Asked Questions : {'Yes' if final_output.get('Candidate_Asked_Question') else 'No'}\")\n","\n","    if final_output.get(\"Candidate_Asked_Questions_List\"):\n","        print(\" Questions from Candidate:\")\n","        for q in final_output[\"Candidate_Asked_Questions_List\"]:\n","            print(f\"   - {q}\")\n","\n","    print(f\"\\n Final Decision  : {final_output.get('Decision', 'N/A')}\")\n","    print(f\" Closing Line    : {final_output.get('Closing_Line', 'N/A')}\")\n","\n","except Exception as e:\n","    print(\"\\n LLM Parsing Error:\", e)\n","\n","    if 'response' in locals():\n","        print(\"\\n Raw response:\")\n","        try:\n","            print(response.text)\n","        except:\n","            print(\"No .text content in response.\")\n","    else:\n","        print(\"No response object was captured.\")\n"],"metadata":{"id":"rl17vZ3X49zf"},"execution_count":null,"outputs":[]}]}